---
title: "STAT 240: Probability and Random Variables"
author: "Bret Larget"
date: "Fall 2024"
output: rmdformats::readthedown
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE,
                      error = TRUE, fig.height = 4)
library(tidyverse)
source("../../scripts/ggprob.R") # This file contains functions custom written for STAT 240 to visualize probability distributions
```

\newcommand{\E}{\mathsf{E}}
\newcommand{\Var}{\mathsf{Var}}

# Overview

## Learning Outcomes

* These lectures will teach you how to:
    - Distinguish between random processes, their outcomes, and the values of random variables
    - Identify what a valid probability distribution is
    - Calculate basic properties of probability distributions with base R and tidyverse commands
    
## Preliminaries

1. Download the file `week06-probability.Rmd` into `STAT240/lecture/week06-probability`.
    
## A Note on Our Semester
    
- Our long-term goal is to cover **statistical inference**, which is a process for making conclusions about a larger population based on a smaller sample of observed data from that population. Many real world problems can be investigated via statistical inference.

- Statistical inference requires some knowledge of probability, distributions, random variables, and statistical models.

- Our goal is *not* to give you a rigorous, comprehensive survey of probability theory; the University has other classes for that!

- Our goal is to **get you the probability knowledge you need to conduct statistical inference**, and will spend a few lectures working towards this goal.

## LaTeX: For Mathematical Notation

- Many future lectures in this class will make use of the LaTeX language for writing mathematical notation using only keys on the keyboard.

- Mathematical notation includes many, many symbols which are not part of the standard keyboard; for example, $\ge$ or $\sigma$.

- Similar to how we can use markdown language to result in *specific* **formatting** `in the knitted file`, LaTeX provides a way to produce these symbols using keys that are in your keyboard, by surrounding an expression in `$dollar signs$`.

- For example, the symbol $\ge$ ("greater than or equal to") is written in LaTeX as `$\ge$`, and $\sigma$ ("sigma") is written as `$\sigma$`.

- We can also create a LaTeX chunk, with two dollar signs on each line delimiting the start and end. Any mathematical notation in the chunk will appear as a larger, centered equation. For example...

$$
\frac{1}{n}\sum_{i=1}^n (x_i - \mu)^2
$$

> You are **not responsible** for learning to write LaTeX, we will never ask you to write LaTeX. However, you are responsible for basic understanding of the mathematical notation it outputs.

# A Primer on Random Variables, Probability, and Distributions

## Random Processes

* Our study of **probability** begins with the notion of a **random process**.

> A **random process** is some "experiment" which produces an unpredictable or outcome. That is, we cannot know for sure what outcome it will produce before it happens. However, we may or may not know the likelihood of each possible outcome.

* The *outcomes* of these random processes do not have to be numeric.

* For example, "flipping a coin twice" is a random process, with the possible outcomes H-H, H-T, T-H, or T-T. ("H" for "heads", "T" for "tails".)

- It is important to acknowledge that a random process **was still random even if it already happened and we know the outcome.**
    - For example, if we conduct the above random process and flip a coin twice, and we get T-H, that does not mean we always had a 100% chance of getting T-H. The original process was still random.

## Random Variables

* The basic forms of statistical inference we will cover in this class will require numeric data - a count of something, a proportion, or a continuous response.

* The outcomes of an experiment do not have to be numeric, such as "heads - tails" from two coin flips; but the **random variable** that arises from the experiment must be a numeric value.

> A **random variable**, informally, is the **single numeric quantity of interest** that can take on a new value every time you run a random process/experiment. Mathematically, it is a function which maps all the possible outcomes of a random process to a real number.

* There are three important features of a random variable:

1. It is **random**; we cannot predict its value beforehand.
2. It is **numeric**; this will often take the form of 0 or 1 for variables like "did this happen or not", but it can also be any real number.
3. It is a **single number** that is generated by one iteration of a random process.

---

* Once again, consider flipping a coin twice, with possible outcomes H-H, H-T, T-H, or T-T.

* A **random variable** based on this random process could be "The total number of heads observed" - let's call this $X$.
    - *Note: We will always refer to random variables with a capital English letter.*

* If the outcome is H-H, $X$ is 2. If the outcome is H-T or T-H, $X$ is 1. If the outcome is T-T, $X$ is 0.

* Note that this value is random, numeric, and reduces the outcome of the experiment to a single number.

---

* Let us extend the experiment to be two rolls of a fair six-sided die. There are 36 possible outcomes to this experiment, including 1 & 1, 1 & 2, 1 & 3, ... 1 & 6, 2 & 1... 6 & 6.

* The outcomes, as they are, are **not** a random variable; 1 & 2 cannot be the outcome of a random variable because it is not a single number.

* However, the *sum* of the two dice rolls would be a random variable - let's call it $X$. (The maximum, or the minimum, or any other reducing function which takes in multiple numbers and returns one, are also a valid random variable here.) 

* If the outcome is 1 & 2, $X$ is 3. If the outcome was 5 & 5, 4 & 6, or 6 & 4, $X$ would be 10.

* $X$ reduces the complex outcome of the experiment down to one number.

## Probability

* We do not know which outcome of a random process is going to occur, and therefore we do not know which value a random variable is going to take on.

* However, we mentioned in the definition of a random process that we sometimes can know the *chance* of each outcome occurring. The field of "probability" is the study of these chances, but more often we will mean...

> The **probability of an outcome** is a single number between 0 and 1 (or equivalently a percentage between 0% and 100%) that indicates how likely you are to get that outcome from the given random process.

* There is an alternative conceptualization of probability which may or may not speak more to you: If we could run the random process infinitely many times, it is the percentage of those times we would get the given outcome.

---

### Sidenote: Probability All Around Us

- In conversation, we frequently reference probability and randomness (sometimes of a process that has already happened) without talking about the formal mechanisms behind it. 

- For example, consider the following statements which describe probability/randomness of a future process:
    - *"I might miss my bus if I don't hurry up."*
    - *"I will need to have a good day on the final to get an A."*
    
- These statements reflect how we often think about probability - about not knowing a future outcome.
    
- However, consider the following statements which describe probability/randomness about a *past* process:
    - *"On another day, we would've won that game."*
    - *"I didn't even leave late or anything, I just hit every red light on the way here."*
    
- These are *also* probabilistic statements which imply a past process was random, even though we know what outcome really occurred.

- Regarding the second example, we can think of the drive somewhere as a random process, which produces a single number: the amount of time it takes you to make it there. 

- Before you drive, you don't know if there will be construction or a road closure, or you'll get unlucky with red lights, or perhaps you will get lucky with green lights. You know about how long it takes on average, but the actual time it takes might vary on any given day.

- The statement "I didn't even leave late or anything" implies you thought the probability of ending up late was low. And it was, you were right! But low probability does not mean impossible, just unusual. 

- There are many sources of randomness beyond those we have discussed in this brief introduction.

- **Probability is everywhere, and underpins how we often think and talk about our lives.**

---

### Let's Get Numeric

* The numeric probabilities associated with coin flips and dice rolls are perhaps the most comfortable to us.
    - The probability of getting "heads" from the flip of a fair coin is 1/2, or 50%.
    - The probability of getting a 3 from rolling a fair, six-sided dice is 1/6, or $\approx$ 16.7%.
    
* We will refer to these probabilities as $P(X = x)$, where $X$ is the random variable, and $x$ is the single numeric value $X$ could take on.

* However, probability can become more complicated very quickly:
    - The probability of rolling two dice and having them sum to 10 is 3/36, or $\approx$ 8%.
    - The probability of a single sampled point from a normal distribution being within one standard deviation of the mean is $\approx$ 68.3%.
    
* We will usually deal with probabilities in the context of a **probability distribution**.

## Probability Distributions

* You can define a probability distribution for the outcomes of the random process (e.g. H-H, H-T, T-H, T-T) or for the values of the random variable (e.g. 0, 1, or 2). We will always talk about it in terms of the random variable.

> A **probability distribution** is, informally, the complete enumeration of how likely each possible outcome of a random process or value of a random variable is.

* For a random variable with a small number of possible outcomes, we can simply list out all probabilities.

* For a random variable with a large or infinite number of possible outcomes, we can't list out every outcome - so we rely on a function describing how to get the probability from a specific input.

* A valid probability distribution always has two intuitive properties.

1. Any possible outcome has a probability between 0% and 100%, inclusive. (*In other words: There's no such thing as negative probability, and 100% is the maximum.*)

2. The sum of the probabilities of all possible outcomes is exactly 100%. (*In other words: something must happen.*)

* For example, the probability distribution for the outcomes of a coin toss is:

Heads: 50%
Tails: 50%

* The probability distribution for the sum of two rolls of a fair sided dice (a random variable) is the following:

```{r}
tibble(x = 2:12, `P(X=x)` = round(c(1:6, 5:1)/36, 2)) %>% print(n = Inf)
```

---

* These probability distributions are able to be written out because the outcomes are **discrete**. If we were dealing with a **continuous** outcome such as the height of a random person, it would be impossible to list out all possible outcomes because there are infinitely many (68.1 inches, 68.11 inches, 68.111 inches...). We will return to this issue in the next section.

## Putting it All Together

* Now that we have looked at each concept individually, let us synthesize them to see a full back-to-front example of random processes, variables, and probability distributions.

1. The **random process**, or "experiment", is the original action whose outcome we cannot know ahead of time, like randomly throwing a dart at a dartboard.

2. The **outcome of that random process** is the spot the dart lands. (Outcomes don't have to be, and often aren't numeric.)

3. The **random variable**, or "quantity of interest", is the single number of interest which comes from a single iteration of the random process. For example, the score of the dart is a random variable, since every dart throw gives you a single score that could vary from throw to throw.

4. The **probability distribution** of the random variable considers all possible values the random variable could take on (for a dartboard, you can get most but not all scores 0 through 60 on a single throw) and assigns them a **probability**.

For example, the probability of getting a bullseye (or in terms of the random variable, $P(X = 50)$) is $\approx$ 0.0001%.

# Discrete vs. Continuous

* We have seen the terms "discrete" and "continuous" before to describe variables in dataframes; we saw it with `scale_*_continuous()` and `scale_*_discrete()`. They apply in a very similar way to probability theory.

* Both discrete and continuous probability distributions/random variables have to follow the same overarching rules described above, but we handle their math in a slightly different way.

## Discrete Outcomes

> **Discrete** outcomes are those which come from a specific set of **distinct** values or categories. If numeric, there must be gaps between the possible values, such as the whole numbers. One could theoretically start from the beginning of the set and start listing the possible values.

* We describe the probability distribution of a discrete random variable with a *probability mass function* (pmf).

* We name it this because one can imagine that there is "mass"/"weight" resting upon each specific, discrete possible value.

* For example, the probability distribution of *the number of heads observed* (random variable) from two coin flips (random process) is discrete:

```{r, echo=FALSE}
gbinom(n=2, p=0.5, size=5) +
    theme(axis.text=element_text(size=20),
        axis.title=element_text(size=22,face="bold")) +
  scale_x_continuous(breaks = c(0, 1, 2))
```


* Notice the two properties being obeyed by this probability distribution:

1. Every possible outcome (0, 1, and 2) has probability in the range [0%, 100%].

2. The sum of all probabilities = 0.25 + 0.5 + 0.25 = 100%.

---

* Even though this outcome is *numeric*, it is still *discrete*.

* The existence of 0 and 1 as outcomes does NOT mean that every number in between (0.1, 0.535, 0.9999) also is a valid outcome. 

## Continuous Outcomes

> **Continuous** outcomes are those which may take any value in a specific range, sometimes over all real numbers. There are infinitely many possible values in this range, considering that numbers can have arbitrary number of digits after the decimal point. 

* Often we will treat a variable as continuous even if we do not *technically* know it to infinite precision or if it exists along a fine grid of technically discrete values.

    * For example, let's assume that in a list of salaries of employees, salaries are expressed to the nearest cent. Technically, there is only a finite number of discrete salaries that are possible. But we would choose to treat this variable as continuous.
    
    * In general, we often choose to treat a variable which is *technically* discrete as continuous if it would be nonsensical to care about each individual value. We do not often go the other way, treating a continuous variable as discrete.
    
---

* We describe the probability distribution of a continuous random variable with a *probability density function* (pdf).
    - This function must never assign negative values or values greater than 1.
    - Furthermore, the area under the curve must equal 1.
    
* Much like `geom_density`, a probability density function takes on a value at all points which usually (but not always) varies in a smooth curve.

* Because the pdf has a value at infinitely many points, it does not make sense to "add up every value", and the probability at a single point loses meaning because there are infinitely many.

* This is why we will rely mostly on area with continuous probability distributions.

* For example, the probability distribution of *the height in inches of American adult males* is continuous.

```{r echo=FALSE}
gnorm(mu=69,sigma=2.9, size = 3) +
  xlab("Height (in.)") +
  ylab("Density") +
  theme(axis.text=element_text(size=20),
        axis.title=element_text(size=22,face="bold"))
```

* More theoretically, a random decimal number between 2 and 5 also follows a continuous distribution.

```{r, echo = FALSE}
a = 2
b = 5
ggplot(tibble(x=c(a,b), y=1/(b-a)), aes(x,y)) +
  geom_line(size=3) +
  geom_segment(aes(xend=x, yend=rep(0,2)), size=3) +
  geom_segment(aes(x=a-1, y=0, xend=a, yend=0), size=3) +
  geom_segment(aes(x=b+1, y=0, xend=b, yend=0), size=3) +
  ylim(c(0, 1/(b-a))) +
  xlim(c(a-1, b+1)) +
  scale_x_continuous(breaks = seq(a-1,b+1)) +
  xlab("X") +
  ylab("Density")+
  ggtitle(paste0("Uniform(",a, ", ", b, ")")) +
  theme(axis.text=element_text(size=20),
        axis.title=element_text(size=22,face="bold"))
```

# Properties of Distributions

* While I think distributions are cool enough on their own, they're also useful beyond just their own set of values.

* Knowing the probability distribution of a random variable allows us to compute useful measures of center and spread.

* The next section of this lecture series will walk us through computing these useful measures from a distribution.

## Mean/Expected Value

> The **mean** or **expected value** of a random variable is the average value it would take on with infinitely many iterations of the random process.

* For discrete variables, the expected value does not have to be a value the random variable can take on. For example, the expected value of a fair roll of a six-sided die is 3.5, even though a single roll cannot return 3.5.

* The calculation of expected value is conceptually similar, but mathematically different for discrete vs. continuous variables.

### Discrete Case

$$
\E(X) = \sum_x x * P(X = x)
$$

* Where $x$ represents each of the possible values that the random variable $X$ can take on.

* The intuition of this formula is that we are taking a modified version of the average of all possible values; but the values $x$ which are more likely to occur are going to have more influence on the final number, through their higher values of $P(X = x)$.

* For example, to calculate the average value of a single roll of a fair six-sided die (let's call this $D$):

$$
\E(D) = 1*P(D = 1) + 2*P(D = 2) + 3*P(D = 3) + 4*P(D = 4) + 5*P(D = 5) + 6*P(D=6)
$$

$$
... = 1*(1/6) + 2*(1/6) + 3*(1/6) + 4*(1/6) + 5*(1/6) + 6*(1/6) = 3.5
$$

### Continuous Case

* The discrete formula does not apply to continuous variables because there are infinitely many possible values. Therefore, we must rely on integrating over an area rather than summing some point-wise probabilities.

$$
\E(X) = \int_{-\infty}^\infty x \,f(x)
\,\mathrm{d}x
$$

In this expression, $f(x)$ is the density function and satisfies

- $f(x) \ge 0$ for all $-\infty < x < \infty$.
  - The density function is never negative.
- $\int_{-\infty}^{\infty} f(x) \, \mathrm{d}x = 1$
  - The total probability is equal to one

* **You will not be asked to evaluate integrals in this class.**

## Standard Deviation & Variance

> The **variance** of a random variable is the expected value of the squared difference from the mean.

### Discrete Case

* Let $\mu = \E(X)$, the expected value of $X$.

$$
\Var(X) = \sum (x-\mu)^2*P(X=x)
$$

* This is similar to the $\E(X)$ formula, except the thing we are summing is now $(x-\mu)^2$, the squared distance from the mean, instead of just $x$.

* For example, to calculate the variance of a single roll of a fair, six-sided dice, once again $D$:

$$
\Var(D) = \sum (x-3.5)^2*P(D=x) = (1 - 3.5)^2*P(D = 1) + + ... + (6-3.5)^2*P(D = x)
$$

$$
... = (1 - 3.5)^2*(1/6) + ... + (6-3.5)^2*(1/6) \approx 2.92.
$$

> The **standard deviation** of a random variable is the square root of its variance, and therefore the variance is the square of the standard deviation.

* Therefore the standard deviation of $D$ above $\approx \sqrt{2.92} \approx = 1.71$; this is on average how far our dice roll will be away from the mean.

### Continuous Case

* Like the continuous analog of the discrete mean, the continuous analog of the discrete variance replaces the sum with an integral.

$$
\Var(X) = \int_{-\infty}^\infty (x-\mu)^2 f(x)\, \mathrm{d}x
$$

---

- The variance is often denoted $\sigma^2$, and the standard deviation is then denoted as $\sigma$. 

- By definition, the variance and the standard deviation cannot be negative.

- These measures show us how varied or spread out the distribution is.

# Some Practice Problems

## Problem 1

A discrete random variable $X$ with possible values $0,1,2,3,4$ has the following partial distribution.

```{r}
## tibble with the distribution
prob1 = tibble(
  x = 0:4,
  p = c(0.15, 0.25, 0.05, 0.35, NA)
)

## long format
prob1

## pretty wide format
prob1 %>%
  pivot_wider(names_from = x, values_from = p) %>% 
  mutate(x = "P(X=x)") %>% 
  relocate(x)
  
```

> What is $P(X = 4)$?

We know for discrete random variables,

$$
\sum_{x} P(X = x) = 1
$$

- Find the missing $P(X=4)$ so that the sum of probabilities is one.
    - sum the other probabilities
    - subtract the total from one
    - set this to the missing probability

```{r}
# Write your code here!
```



## Problem 2

> What is the mean of the random variable with the previous distribution?

$$
\mu = E(X) = \sum_{x=0}^4 x * P(X=x)
$$

```{r}
# write your code here!
```


- Note that the mean (expected value) is a **weighted average** of the possible values of the random variable, weighted by their probabilities.

## Problem 3

> What are the variance and standard deviation of the random variable from problem 1?

$$
\sigma^2 = \Var(X) = \sum_{x=0}^4 (x - \mu)^2 P(X=x)
$$



## Problem 4

> Draw a graph of the discrete distribution.

- Use line segments to represent the probabilities

```{r}
# Write your code here
```


## Problem 5

> Add a dashed red line at the mean and dotted black lines one standard deviation above and below the mean.

```{r}
# Write your code here
```


- Note that the mean is the *balancing point* of the distribution
    - It does not need to be a possible value of the distribution
    
- The majority of the probability is within one standard deviation of the mean

- But there is some remaining probability outside of this interval

## Problem 6

> Find the probability within one standard deviation of the mean.

```{r}
# Write your code here.
```

## Problem 7

Consider the random experiment of flipping a coin three times.

### a) 

List out every possible **outcome** of the three coin flips.

### b)

What are the probabilities of each individual outcome?

## Problem 8

Consider the random variable $X$, which counts the number of heads from three coin flips.

### a)

What are the possible values of $X$? Which outcomes map to those values?

### b) 

What is the probability distribution of $X$?

# Solutions

## Problem 1

```{r}
## tibble with the distribution
prob1 = tibble(
  x = 0:4,
  p = c(0.15, 0.25, 0.05, 0.35, NA)
)

## long format
prob1

## pretty wide format
prob1 %>%
  pivot_wider(names_from = x, values_from = p) %>% 
  mutate(x = "P(X=x)") %>% 
  relocate(x)
```

```{r}
partial_sum = prob1 %>% 
  filter(x != 4) %>% 
  summarize(sum_p = sum(p)) %>% 
  pull(sum_p) # new function; dataframe %>% pull(x) is the same as dataframe$x, just more convenient for piping workflow.

p4 = 1 - partial_sum

p4

prob1 = prob1 %>% 
  mutate(p = case_when(
    !is.na(p) ~ p,
    TRUE ~ p4))

## long format
prob1

## pretty wide format
prob1 %>%
  pivot_wider(names_from = x, values_from = p) %>% 
  mutate(x = "P(X=x)") %>% 
  relocate(x)

```

## Problem 2

```{r}
## Calculate the mean using base R code
x = prob1$x
p = prob1$p
mu = sum(x*p)
mu
```

## Problem 3

```{r}
## Base R calculation
## Variance
sigma2 = sum((x-mu)^2*p)
sigma2

## Standard deviation
sigma = sqrt(sigma2)
sigma
```

## Problem 4

```{r}
plot1 = ggplot(prob1, aes(x = x, y = p)) +
  geom_segment(aes(xend = x, yend = 0), color = "blue", size=2) +
  geom_hline(yintercept = 0) +
  ylab("P(X=x)") +
  ggtitle("Distribution of X")

plot1
```

## Problem 5

```{r}
plot1 +
  geom_vline(xintercept = mu, color = "red", linetype = "dashed") +
  geom_vline(xintercept = mu + c(-1,1)*sigma,
             color = "black",
             linetype = "dotted")
```

## Problem 6


```{r}
## base R calculation
p6 = sum(p[x >= mu - sigma & x <= mu + sigma])
p6
```

```{r}
## tidyverse calculation
prob6 = prob1 %>% 
  filter(x >= mu - sigma & x <= mu + sigma) %>% 
  summarize(prob = sum(p))

prob6
```

## Problem 7

Consider the random experiment of flipping a coin three times.

### a) 

List out every possible **outcome** of the three coin flips.

> HHH, HHT, HTH, HTT, TTT, TTH, THT, THH

### b)

What are the probabilities of each individual outcome?

> Every individual outcome has probability 0.5 * 0.5 * 0.5 = 0.125.

> Another way to arrive at that probability: they're all equally likely, and they must sum to one, and there's 8 outcomes, so each must have probability 1/8 = 0.125.

## Problem 8

Consider the random variable $X$, which counts the number of heads from three coin flips.

### a)

What are the possible values of $X$? Which outcomes map to those values?

> TTT gives X a value of 0. HTT, THT, and TTH give X a value of 1. THH and HHT and HTH give X a value of 2. HHH gives X a value of 3.

### b) 

What is the probability distribution of the values of $X$?

$P(X = 0) = 1/8$

$P(X = 1) = 3/8$

$P(X = 2) = 3/8$

$P(X = 3) = 1/8$.




